{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf067910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8fa91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3788\\2898610457.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  use_ollama=Ollama(model=\"llama3.2:1b\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "use_ollama=Ollama(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0151f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"tell about today's weather\"\n",
    "result=use_ollama.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eccc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not aware of your current location or the date. However, I can provide you with general information about the typical weather patterns in different parts of the world.\n",
      "\n",
      "If you'd like to know the current weather in a specific city or region, please let me know the city name and country it's located in, and I'll do my best to provide you with the latest forecast.\n",
      "\n",
      "Alternatively, if you're looking for a general overview of the typical weather patterns in different regions, here are some examples:\n",
      "\n",
      "* In the Northern Hemisphere:\n",
      "\t+ Spring: April to June is usually warm and sunny, while July to September can be hot and dry.\n",
      "\t+ Summer: August to October can be hot and humid, with occasional tropical storms.\n",
      "\t+ Autumn: November to March can be cool and wet, with significant rainfall during this time.\n",
      "* In the Southern Hemisphere:\n",
      "\t+ Spring: December to February is usually warm and sunny, while March to May can be hot and dry.\n",
      "\t+ Summer: June to August can be hot and humid, with occasional tropical storms.\n",
      "\t+ Autumn: September to November can be cool and wet, with significant rainfall during this time.\n",
      "\n",
      "Keep in mind that these are general patterns and can vary significantly depending on your specific location and the time of year.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "286ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOw we try to give text from pdf , text file and from url and then use our model to give answer according to that resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1130ca",
   "metadata": {},
   "source": [
    "we are going to create a generative app which will give answer according to what we want \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ac2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a chatprompt template by which we are giving instrution how to work it system and user we are \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a student \"),\n",
    "        (\"user\", \"{userquestion}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c39569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|use_ollama\n",
    "result=chain.invoke({\"userquestion\":\"how you feel if teacher used to take attendence online\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb0bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a student, I would feel really frustrated and annoyed if my teacher was taking attendance online. Here's why:\n",
      "\n",
      "Firstly, it's not as effective as having students physically present in class. When students are physically present, they can raise their hands, walk around the room, or ask questions which helps to engage them with the material. However, when students are online, it can be difficult for me to gauge their level of understanding and engagement.\n",
      "\n",
      "Secondly, it's hard to determine if a student is actually in class or not. If I'm having trouble getting a response from them even after asking multiple times, it makes me wonder why they're not present.\n",
      "\n",
      "Thirdly, some students may have technical issues or be experiencing online distractions which can affect their ability to participate effectively in the class discussion.\n",
      "\n",
      "Lastly, online attendance doesn't provide any feedback on my performance or participation. It's like I'm just a number on a list, rather than a real student who is actively learning and participating.\n",
      "\n",
      "Overall, if my teacher was taking attendance online, it would feel like they're not taking me seriously as a student, which can be demotivating and affect my engagement with the material.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b6256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b7869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
